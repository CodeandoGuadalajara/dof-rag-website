---
title: >-
  La batalla de los embeddings: cuando tres modelos de IA compiten por entender
  el espa침ol gubernamental
date: 2025-08-12T06:00:00.000Z
author: Equipo DOF-RAG
description: >-
  Un an치lisis comparativo entre tres modelos de embeddings (Nomic Embed, Gemini,
  Jina) evaluando velocidad, calidad y estabilidad en b칰squeda vectorial para
  documentos oficiales mexicanos.
image: /images/posts/2025/08/comparacion-embeddings/models_battel.jpeg
tags:
  - Nomic
  - Jina
  - Gemini
  - DuckDB
  - b칰squeda-vectorial
  - embeddings
  - DOF-RAG
---

# Cuando los algoritmos se enfrentan al lenguaje burocr치tico mexicano

En el mundo de la inteligencia artificial, uno de los an치lisis m치s importantes en el 치mbito de procesamiento de lenguaje natural es evaluar c칩mo diferentes modelos de embeddings comprenden y representan el complejo universo del lenguaje gubernamental mexicano. En este estudio analizamos tres modelos de embeddings: **Nomic Embed** (modelo local), **Gemini** (API de Google), y **Jina** (especializado en b칰squeda vectorial). Su objetivo: descifrar, entender y hacer b칰squedas efectivas en miles de documentos del Diario Oficial de la Federaci칩n.

Los resultados revelan diferencias significativas entre velocidad, precisi칩n y las ventajas operacionales de soluciones locales versus APIs en la nube.

### Hallazgos principales del an치lisis

**Principales conclusiones del estudio:**

1. **Gemini ofrece la calidad superior de respuestas**, seguido por Jina con calidad equivalente pero perspectiva diferente, y Nomic Embed con calidad funcional
2. **Las m칠tricas de similitud presentan diferencias de rendimiento pr치cticamente despreciables** (\~2ms)
3. **Nomic Embed lidera en rendimiento operacional y estabilidad**, pero requiere datos muy limpios, mientras que Gemini y Jina son robustos ante datos de calidad variable
4. **Ambas m칠tricas recuperan contenido id칠ntico**, diferenci치ndose 칰nicamente en la escala de puntuaci칩n de relevancia
5. **La decisi칩n de modelo debe priorizar calidad de respuestas vs autonom칤a operacional** seg칰n las necesidades espec칤ficas del negocio

## El desaf칤o: an치lisis de b칰squeda vectorial en documentos gubernamentales

Cuando construimos sistemas de Recuperaci칩n Aumentada por Generaci칩n (RAG) como DOF-RAG, nos enfrentamos a un problema que va mucho m치s all치 de la b칰squeda tradicional de palabras clave. Los ciudadanos no buscan exactamente las mismas palabras que aparecen en los documentos oficiales. Alguien podr칤a preguntar "쮺칩mo me afilio al IMSS-Bienestar?" mientras que el documento oficial habla de "procedimientos de incorporaci칩n al r칠gimen de seguridad social".

Aqu칤 es donde entran los **embeddings vectoriales**: representaciones matem치ticas que capturan el *significado sem치ntico* del texto, permitiendo que el sistema entienda que ambas frases se refieren al mismo concepto, aunque usen palabras completamente diferentes.

Este an치lisis se basa en **42 consultas representativas** procesadas sobre **m치s de 5,000 fragmentos de documentos del DOF**, evaluando tanto velocidad de b칰squeda como calidad de respuestas mediante **m칠todos nativos de DuckDB**.

Pero surge la pregunta clave: **쯤u칠 modelo de embeddings funciona mejor para documentos gubernamentales mexicanos?** Y m치s importante a칰n: **쯜mporta realmente si usamos distancia euclidiana (L2) o similitud coseno?**

## Los modelos evaluados: caracter칤sticas y especificaciones t칠cnicas

### 游 Nomic Embed: Modelo local

**Caracter칤sticas t칠cnicas:** Un modelo completamente local (`modernbert-embed-base`) que opera sin dependencias de internet.

**Especificaciones:**

* **Dimensiones:** 768 (arquitectura compacta y eficiente)
* **Tama침o:** \~596 MB (factible para hardware est치ndar)
* **Ventaja principal:** Latencia de red nula
* **Perfil operacional:** Modelo confiable para entornos con requisitos de disponibilidad constante

**Justificaci칩n de selecci칩n:** Representa la independencia operacional total. En escenarios donde la conectividad es limitada, las APIs no est치n disponibles, o existen restricciones presupuestarias, Nomic Embed mantiene funcionalidad completa.

### 游 Gemini: API comercial de Google

**Caracter칤sticas t칠cnicas:** Modelo de embeddings de Google con infraestructura cloud empresarial.

**Especificaciones:**

* **Dimensiones:** 1536 (alta dimensionalidad para representaci칩n sem치ntica compleja)
* **Velocidad:** 3-5 segundos por consulta
* **Calidad:** Comprensi칩n contextual avanzada
* **Limitaciones:** 15 peticiones por minuto, 1000 peticiones por d칤a (plan gratuito)

**Justificaci칩n de selecci칩n:** Gemini representa el estado actual de embeddings comerciales, combinando calidad sem치ntica superior con la estabilidad y confiabilidad de la infraestructura de Google.

**Consideraciones del plan gratuito:** Al utilizar el tier gratuito de Gemini, estamos sujetos a limitaciones de 15 peticiones por minuto y 1000 peticiones diarias.

### 游꿢 Jina: API especializada en embeddings

**Caracter칤sticas t칠cnicas:** Empresa especializada exclusivamente en embeddings y b칰squeda vectorial.

**Especificaciones:**

* **Dimensiones:** 1024 (dimensionalidad intermedia)
* **Especializaci칩n:** Optimizaci칩n espec칤fica para b칰squeda vectorial
* **Plan:** Gratuito con 10 millones de tokens disponibles
* **Perfil operacional:** Modelo especializado con rendimiento variable seg칰n disponibilidad del servicio

**Justificaci칩n de selecci칩n:** Jina ofrece una perspectiva especializada en el ecosistema de embeddings, proporcionando un punto de comparaci칩n valioso entre soluciones locales y APIs comerciales de prop칩sito general.

**Limitaciones del plan gratuito:** Jina ofrece 10 millones de tokens para procesar, pero al ser un plan experimental, las peticiones se procesan con baja prioridad, resultando en tiempos de respuesta variables.

### Consideraciones de servicios en la nube

**Tanto Gemini como Jina operan bajo planes gratuitos**, lo que introduce algunas limitaciones operacionales importantes que explican parte de la variabilidad observada en los resultados, especialmente para Jina que mostr칩 tiempos de respuesta de 30-50 segundos promedio.

Esta realidad hace que **Nomic Embed, pese a su menor calidad sem치ntica, ofrezca ventajas significativas de autonom칤a y predictibilidad operacional**.

## Metodolog칤a de evaluaci칩n: m칠todos nativos de DuckDB

Para garantizar una comparaci칩n equitativa entre modelos, utilizamos los **m칠todos nativos de DuckDB** - funciones optimizadas (`array_cosine_similarity()` y `array_distance()`) que son **35-50 veces m치s r치pidas** que las implementaciones manuales en Python.

**Impacto en rendimiento:** La diferencia pr치ctica es sustancial: pasar de b칰squedas que requer칤an 500-800ms a b칰squedas optimizadas de 9-16ms. Esta mejora es comparable a la diferencia entre procesar datos manualmente versus utilizar algoritmos altamente optimizados.

### L2 vs Coseno: la eterna pregunta

**Distancia L2 (Euclidiana):** Mide qu칠 tan "lejos" est치n dos vectores en el espacio matem치tico. Como medir la distancia entre dos puntos en un mapa.

**Similitud Coseno:** Mide qu칠 tan "alineados" est치n dos vectores, ignorando su magnitud. Como medir si dos flechas apuntan en la misma direcci칩n, sin importar su tama침o.

La pregunta que todos se hacen: **쯜mporta cu치l usar?** Spoiler: menos de lo que pensar칤as.

## Los resultados: cuando los n칰meros hablan por s칤 solos

### An치lisis 1: Velocidad de b칰squeda vectorial

| Modelo          | L2 (ms) | Coseno (ms) | Diferencia | Observaci칩n                   |
| --------------- | ------- | ----------- | ---------- | ----------------------------- |
| **Nomic Embed** | 14.03   | 12.62       | +1.41ms    | Coseno ligeramente m치s r치pido |
| **Gemini**      | 16.20   | 14.12       | +2.08ms    | Coseno ligeramente m치s r치pido |
| **Jina**        | 11.69   | 9.21        | +2.48ms    | Coseno ligeramente m치s r치pido |

**Hallazgo importante:** La diferencia promedio de \~2ms entre L2 y Coseno es pr치cticamente despreciable para aplicaciones en producci칩n. Esta diferencia es comparable a debatir si una tarea se completa en 4.012 segundos versus 4.014 segundos: t칠cnicamente medible, pr치cticamente irrelevante.

### An치lisis 2: Rendimiento total (embedding + b칰squeda)

Este an치lisis examina no solo la velocidad de b칰squeda, sino tambi칠n la velocidad de procesamiento para generar embeddings de nuevas consultas.

#### M칠trica L2

| Posici칩n | Modelo          | Tiempo Total | Consultas/seg | Chunks/seg |
| -------- | --------------- | ------------ | ------------- | ---------- |
| 1춿       | **Nomic Embed** | 177ms        | 5.65          | 356.3      |
| 2춿       | **Gemini**      | 412ms        | 2.43          | 308.6      |
| 3춿       | **Jina**        | 49,684ms     | 0.02          | 427.5      |

#### M칠trica Coseno

| Posici칩n | Modelo          | Tiempo Total | Consultas/seg | Chunks/seg |
| -------- | --------------- | ------------ | ------------- | ---------- |
| 1춿       | **Nomic Embed** | 201ms        | 4.97          | 396.2      |
| 2춿       | **Gemini**      | 391ms        | 2.55          | 354.2      |
| 3춿       | **Jina**        | 34,944ms     | 0.03          | 542.7      |

**Hallazgo importante:** Nomic Embed supera significativamente a los modelos basados en API en rendimiento total. Esta ventaja se debe a que mientras Gemini y Jina requieren transmisi칩n de datos a trav칠s de internet, Nomic Embed procesa todo localmente. La diferencia es comparable a consultar informaci칩n almacenada localmente versus realizar una llamada telef칩nica a larga distancia.

#### Definici칩n de m칠tricas de rendimiento

**Consultas/seg (Queries per Second):** Mide la **velocidad de procesamiento completo** de una consulta, incluyendo tanto la generaci칩n del embedding como la b칰squeda vectorial. Se calcula como el inverso del tiempo total promedio. Esta m칠trica representa la **capacidad del sistema para atender consultas de usuarios finales**.

**Chunks/seg (Chunks per Second):** Mide la **velocidad de procesamiento durante la fase de b칰squeda 칰nicamente**, calculando cu치ntos fragmentos de documento pueden ser procesados por segundo durante la comparaci칩n vectorial. Esta m칠trica eval칰a la **eficiencia del motor de b칰squeda** independiente de la generaci칩n de embeddings.

### An치lisis 3: Calidad de respuestas

Evaluaci칩n basada en la consulta: *"쮺칩mo pueden las personas ciudadanas afiliarse al IMSS-Bienestar?"*

#### Relevancia con L2

| Modelo          | Relevancia Promedio | Categor칤a | Observaci칩n                                |
| --------------- | ------------------- | --------- | ------------------------------------------ |
| **Gemini**      | 94.8%               | Excelente | Respuestas precisas y contextuales         |
| **Jina**        | 92.2%               | Excelente | Calidad equiparable, perspectiva diferente |
| **Nomic Embed** | 92.0%               | Muy buena | Funcional y confiable                      |

#### Relevancia con Coseno

| Modelo          | Relevancia Promedio | Categor칤a | Observaci칩n                   |
| --------------- | ------------------- | --------- | ----------------------------- |
| **Jina**        | 92.2%               | Excelente | Consistente en ambas m칠tricas |
| **Gemini**      | 68.1%               | Aceptable | Puntuaci칩n m치s conservadora   |
| **Nomic Embed** | 61.9%               | Aceptable | Puntuaci칩n m치s conservadora   |

**Hallazgo importante:** Ambas m칠tricas recuperan exactamente los mismos fragmentos de texto, pero L2 genera puntuaciones 30-35% m치s optimistas que Coseno. L2 aplica una transformaci칩n logar칤tmica que favorece puntuaciones altas, mientras que Coseno proporciona una evaluaci칩n m치s directa de la similitud angular.

### An치lisis 4: Estabilidad operacional

La variabilidad en el rendimiento es un factor cr칤tico para sistemas en producci칩n. Un modelo puede ser r치pido y preciso, pero la inconsistencia operacional puede generar problemas significativos.

#### Desviaci칩n est치ndar en L2

| Modelo          | Embedding (ms) | B칰squeda (ms) | Evaluaci칩n                        |
| --------------- | -------------- | ------------- | --------------------------------- |
| **Gemini**      | 274.49         | 10.21         | Estable y confiable               |
| **Nomic Embed** | 1958.16        | 9.06          | Muy estable (procesamiento local) |
| **Jina**        | 4607.21        | 4.59          | Variable (servicio gratuito)      |

**Consideraciones operacionales:** Jina, como servicio experimental gratuito, presenta la mayor variabilidad en rendimiento. Gemini mantiene mayor consistencia gracias a su infraestructura empresarial. Nomic Embed demuestra estabilidad predecible debido a su naturaleza local.

### Robustez ante calidad de datos

Un hallazgo importante del an치lisis es que **Nomic Embed requiere datos muy limpios para un rendimiento 칩ptimo**, mientras que **Gemini y Jina demuestran mayor robustez ante datos de calidad variable**.

Los datos no limpios afectan a todos los modelos incrementando:

* **Consumo de tokens y tiempo de procesamiento**
* **Agotamiento acelerado de cuotas** (relevante para APIs)
* **Sobrecarga computacional** por contenido mal estructurado

Esta consideraci칩n es importante para la selecci칩n de modelo seg칰n la calidad de los datos de entrada disponibles.

## El an치lisis visual: estructura del espacio vectorial

### 쯈u칠 nos dicen las visualizaciones?

Nuestro an치lisis incluy칩 extensas visualizaciones que revelan patrones importantes:

**Gr치ficos de rendimiento:** Muestran claramente que la b칰squeda vectorial es siempre ultrarr치pida (menos de 17ms), mientras que la generaci칩n de embeddings domina el tiempo total. Es como descubrir que en una carrera de relevos, todos los corredores son igualmente r치pidos, pero algunos tardan mucho m치s en recibir la estafeta.

### M칠tricas de rendimiento

#### Comparaci칩n de velocidad (Performance Comparison)

Las gr치ficas comparativas revelan que Nomic Embed es consistentemente el m치s r치pido en tiempo total, seguido por Gemini, mientras que Jina presenta alta variabilidad por las limitaciones del servicio gratuito.

* **M칠trica Coseno:** 
  ![](/images/posts/2025/08/comparacion-embeddings/metrics_native_coseno/performance_comparison_native.png)
* **M칠trica L2:** 
  ![](/images/posts/2025/08/comparacion-embeddings/metrics_native_l2/performance_comparison_native.png)

#### An치lisis de throughput (Velocity & Throughput Comparison)

Estas visualizaciones confirman la superioridad de Nomic Embed en consultas/seg y la eficiencia equivalente en chunks/seg entre todos los modelos.

* **Velocity Comparison Coseno:**

![](/images/posts/2025/08/comparacion-embeddings/metrics_native_coseno/velocity_comparison_native.png)

* **Velocity Comparison L2:** ![](/images/posts/2025/08/comparacion-embeddings/metrics_native_l2/velocity_comparison_native.png)
* **Throughput Comparison Coseno:**

![](/images/posts/2025/08/comparacion-embeddings/metrics_native_coseno/throughput_comparison_native.png)

* **Throughput Comparison L2:** 

![](/images/posts/2025/08/comparacion-embeddings/metrics_native_l2/throughput_comparison_native.png)

#### Estabilidad temporal (Boxplots y Histogramas)

Los boxplots revelan que Gemini mantiene estabilidad empresarial, Nomic Embed presenta variaciones predecibles locales, y Jina muestra mayor dispersi칩n por las limitaciones del tier gratuito.

* **Performance Boxplots Coseno:**![](/images/posts/2025/08/comparacion-embeddings/metrics_native_coseno/performance_boxplots_native.png)
* **Performance Boxplots L2:** ![](/images/posts/2025/08/comparacion-embeddings/metrics_native_l2/performance_boxplots_native.png)
* **Timing Histograms Coseno:** ![](/images/posts/2025/08/comparacion-embeddings/metrics_native_coseno/timing_histograms_native.png)
* **Timing Histograms L2:** ![](/images/posts/2025/08/comparacion-embeddings/metrics_native_l2/timing_histograms_native.png)
* **Timing Scatter Coseno:** ![](/images/posts/2025/08/comparacion-embeddings/metrics_native_coseno/timing_scatter_native.png)\`\`
* **Timing Scatter L2:** ![](/images/posts/2025/08/comparacion-embeddings/metrics_native_l2/timing_scatter_native.png)\`\`

### Visualizaciones del espacio vectorial

**Proyecciones t-SNE:** Estas representaciones 2D del espacio vectorial multidimensional revelaron un hallazgo crucial: **la estructura espacial de los embeddings es pr치cticamente id칠ntica entre L2 y Coseno**. Los documentos se agrupan de la misma manera, las consultas caen en los mismos lugares. Solo cambia la forma de medir las distancias.

#### Estructura de clusters por modelo

Las proyecciones t-SNE muestran c칩mo cada modelo organiza el contenido en el espacio vectorial:

* **Gemini Chunks:**
* ![](/images/posts/2025/08/comparacion-embeddings/tsne_native_coseno/tsne_gemini_chunks_native.png)
* **Jina Chunks:** ![](/images/posts/2025/08/comparacion-embeddings/tsne_native_coseno/tsne_jina_chunks_native.png)
* **Nomic Embed Chunks:** ![](/images/posts/2025/08/comparacion-embeddings/tsne_native_coseno/tsne_nomic_chunks_native.png)

#### An치lisis de overlays por modelo y m칠trica

Los overlays revelan c칩mo las consultas se posicionan respecto a los clusters de contenido:

**Gemini Overlays:**

* ![](/images/posts/2025/08/comparacion-embeddings/tsne_native_coseno/tsne_gemini_overlay_native.png)

**Jina Overlays:**

* **Coseno:**![](/images/posts/2025/08/comparacion-embeddings/tsne_native_coseno/tsne_jina_overlay_native.png)
* **L2:** ![](/images/posts/2025/08/comparacion-embeddings/tsne_native_l2/tsne_jina_overlay_native.png)

**Nomic Embed Overlays:**

* ![](/images/posts/2025/08/comparacion-embeddings/tsne_native_coseno/tsne_nomic_overlay_native.png)

**Visualizaciones por modelo:**

* **Gemini y Nomic Embed:** Los overlays son pr치cticamente id칠nticos entre m칠tricas
* **Jina:** Es el 칰nico modelo que presenta ligeras variaciones en los overlays entre m칠tricas

Las visualizaciones apoyan las conclusiones num칠ricas: **misma recuperaci칩n de contenido, diferencias solo en la escala de relevancia**.

## La dimensionalidad importa (pero no como esperar칤as)

Un hallazgo contraintuitivo: **Jina (1024D) es el m치s r치pido en b칰squedas**, seguido por Nomic Embed (768D) y finalmente Gemini (1536D). Esto desaf칤a la intuici칩n de que m치s dimensiones = m치s lentitud. La realidad es que la optimizaci칩n del algoritmo y la implementaci칩n importan m치s que el n칰mero bruto de dimensiones.

## Aspectos t칠cnicos: bajo el cap칩

### C칩mo convertimos distancias en porcentajes

**Para L2 (Distancia Euclidiana):**

```
relevancia = 100.0 / (1.0 + distancia / 10.0)
```

Esta f칩rmula logar칤tmica comprime las diferencias, haciendo que distancias peque침as se traduzcan en relevencias muy altas.

**Para Coseno (Similitud Angular):**

```
relevancia = similitud x 100.0
```

Una conversi칩n directa y lineal que refleja exactamente la similitud angular.

### Los l칤mites operacionales

Los servicios de API presentan limitaciones que influyen en el rendimiento:

**Gemini:** 15 peticiones por minuto, 1000 peticiones por d칤a
**Jina:** 10 millones de tokens, procesamiento con baja prioridad

Estas limitaciones explican parcialmente la variabilidad observada en los tiempos de respuesta y hacen que soluciones locales como Nomic Embed ofrezcan ventajas de predictibilidad.

## Conclusiones: cuando la teor칤a se encuentra con la realidad

### Evaluaci칩n comparativa final

**Para velocidad y autonom칤a operacional:** **Nomic Embed** demuestra superioridad clara. Sin dependencias externas, sin l칤mites de API, con rendimiento predecible. Representa una soluci칩n robusta y aut칩noma para entornos con requisitos de disponibilidad constante.

**Para calidad sem치ntica superior:** **Gemini** ofrece la mejor experiencia cuando la precisi칩n es prioritaria. Proporciona embeddings de alta calidad con infraestructura empresarial confiable, aunque con limitaciones de uso que requieren planificaci칩n.

**Para balance calidad-disponibilidad:** **Jina** ofrece buen rendimiento cuando el servicio opera 칩ptimamente. 칔til como alternativa especializada, aunque con variabilidad inherente a servicios gratuitos.

### L2 vs Coseno: an치lisis comparativo

Despu칠s de 42 consultas y an치lisis exhaustivos, los datos muestran que **ambas m칠tricas son funcionalmente equivalentes**. Las diferencias principales:

* Recuperan exactamente el mismo contenido
* Diferencias de velocidad m칤nimas (\~2ms)
* Mantienen estructura espacial id칠ntica
* Solo difieren en escalas de puntuaci칩n

La selecci칩n entre ambas puede basarse en preferencias de interpretaci칩n: Coseno ofrece puntuaciones m치s conservadoras y directamente interpretables, mientras que L2 proporciona puntuaciones m치s optimistas debido a su transformaci칩n logar칤tmica.

### La estrategia h칤brida: lo mejor de ambos mundos

Para proyectos grandes como DOF-RAG, la soluci칩n 칩ptima es una **estrategia h칤brida**:

1. **Gemini para documentos cr칤ticos** donde la precisi칩n es fundamental
2. **Nomic Embed para procesamiento masivo** donde podemos aceptar un margen de error mayor
3. **Jina como respaldo** para casos especiales que requieren una perspectiva diferente

### Recomendaciones pr치cticas

**Para autonom칤a operacional completa:** Nomic Embed es la elecci칩n 칩ptima. El sistema nunca depender치 de APIs externas y mantendr치 rendimiento predecible.

**Para m치xima calidad sem치ntica:** Gemini ofrece la mejor experiencia cuando la precisi칩n es prioritaria, aunque requiere gesti칩n de l칤mites de API.

**Para experimentaci칩n con presupuesto limitado:** Jina proporciona una opci칩n viable para prototipos, aunque con variabilidad en tiempos de respuesta.

**Sobre selecci칩n de m칠trica:** Coseno para puntuaciones conservadoras e interpretables; L2 para puntuaciones optimistas. Ambas ofrecen rendimiento equivalente en recuperaci칩n de contenido.

## Reflexiones finales: el futuro de la b칰squeda sem치ntica

Este an치lisis nos ha ense침ado que en el mundo de los embeddings, como en muchos aspectos de la tecnolog칤a, no existe una soluci칩n 칰nica que sea perfecta para todos los casos. La elecci칩n del modelo correcto depende de tus prioridades espec칤ficas: 쯔utonom칤a o calidad? 쯨elocidad o precisi칩n? 쯖osto o rendimiento?

Lo que s칤 queda claro es que los embeddings vectoriales han democratizado la b칰squeda sem치ntica sofisticada. Modelos que hace unos a침os requer칤an infraestructuras millonarias ahora pueden ejecutarse en una laptop modesta. El futuro de la b칰squeda inteligente no est치 en manos de unos pocos gigantes tecnol칩gicos, sino al alcance de cualquiera con curiosidad suficiente para experimentar.

Y quiz치s esa sea la lecci칩n m치s importante: en la era de la IA, el conocimiento t칠cnico sigue siendo poder, pero el poder real est치 en saber c칩mo aplicar esas herramientas para resolver problemas reales de personas reales.

***

*Este an치lisis forma parte de nuestro proyecto DOF-RAG para hacer m치s accesible la informaci칩n gubernamental mexicana. Para m치s detalles t칠cnicos, metodolog칤a completa y acceso al c칩digo fuente, consulta [nuestro repositorio](https://github.com/CodeandoGuadalajara/dof-rag).*

**Datos del an치lisis:**

* **Per칤odo de evaluaci칩n:** Agosto 2025
* **Consultas analizadas:** 42 preguntas representativas
* **Fragmentos procesados:** M치s de 1000 chunks de documentos DOF
* **Herramientas utilizadas:** DuckDB, Python, m칠todos nativos de similitud vectorial
