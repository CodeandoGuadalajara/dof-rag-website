---
title: >-
  La batalla de los embeddings: cuando tres modelos de IA compiten por entender
  el espa√±ol gubernamental
date: 2025-08-12T06:00:00.000Z
author: Equipo DOF-RAG
description: >-
  Un an√°lisis comparativo entre tres modelos de embeddings (Nomic Embed, Gemini,
  Jina) evaluando velocidad, calidad y estabilidad en b√∫squeda vectorial para
  documentos oficiales mexicanos.
image: /images/posts/2025/08/comparacion-embeddings/models_battel.jpeg
tags:
  - Nomic
  - Jina
  - Gemini
  - DuckDB
  - b√∫squeda-vectorial
  - embeddings
  - DOF-RAG
---

# Cuando los algoritmos se enfrentan al lenguaje burocr√°tico mexicano

En el mundo de la inteligencia artificial, uno de los an√°lisis m√°s importantes en el √°mbito de procesamiento de lenguaje natural es evaluar c√≥mo diferentes modelos de embeddings comprenden y representan el complejo universo del lenguaje gubernamental mexicano. En este estudio analizamos tres modelos de embeddings: **Nomic Embed** (modelo local), **Gemini** (API de Google), y **Jina** (especializado en b√∫squeda vectorial). Su objetivo: descifrar, entender y hacer b√∫squedas efectivas en miles de documentos del Diario Oficial de la Federaci√≥n.

Los resultados revelan diferencias significativas entre velocidad, precisi√≥n y las ventajas operacionales de soluciones locales versus APIs en la nube.

### Hallazgos principales del an√°lisis

**Principales conclusiones del estudio:**

1. **Gemini ofrece la calidad superior de respuestas**, seguido por Jina con calidad equivalente pero perspectiva diferente, y Nomic Embed con calidad funcional
2. **Las m√©tricas de similitud presentan diferencias de rendimiento pr√°cticamente despreciables** (\~2ms)
3. **Nomic Embed lidera en rendimiento operacional y estabilidad**, pero requiere datos muy limpios, mientras que Gemini y Jina son robustos ante datos de calidad variable
4. **Ambas m√©tricas recuperan contenido id√©ntico**, diferenci√°ndose √∫nicamente en la escala de puntuaci√≥n de relevancia
5. **La decisi√≥n de modelo debe priorizar calidad de respuestas vs autonom√≠a operacional** seg√∫n las necesidades espec√≠ficas del negocio

## El desaf√≠o: an√°lisis de b√∫squeda vectorial en documentos gubernamentales

Cuando construimos sistemas de Recuperaci√≥n Aumentada por Generaci√≥n (RAG) como DOF-RAG, nos enfrentamos a un problema que va mucho m√°s all√° de la b√∫squeda tradicional de palabras clave. Los ciudadanos no buscan exactamente las mismas palabras que aparecen en los documentos oficiales. Alguien podr√≠a preguntar "¬øC√≥mo me afilio al IMSS-Bienestar?" mientras que el documento oficial habla de "procedimientos de incorporaci√≥n al r√©gimen de seguridad social".

Aqu√≠ es donde entran los **embeddings vectoriales**: representaciones matem√°ticas que capturan el *significado sem√°ntico* del texto, permitiendo que el sistema entienda que ambas frases se refieren al mismo concepto, aunque usen palabras completamente diferentes.

Este an√°lisis se basa en **42 consultas representativas** procesadas sobre **m√°s de 5,000 fragmentos de documentos del DOF**, evaluando tanto velocidad de b√∫squeda como calidad de respuestas mediante **m√©todos nativos de DuckDB**.

Pero surge la pregunta clave: **¬øqu√© modelo de embeddings funciona mejor para documentos gubernamentales mexicanos?** Y m√°s importante a√∫n: **¬øimporta realmente si usamos distancia euclidiana (L2) o similitud coseno?**

## Los modelos evaluados: caracter√≠sticas y especificaciones t√©cnicas

### üè† Nomic Embed: Modelo local

**Caracter√≠sticas t√©cnicas:** Un modelo completamente local (`modernbert-embed-base`) que opera sin dependencias de internet.

**Especificaciones:**

* **Dimensiones:** 768 (arquitectura compacta y eficiente)
* **Tama√±o:** \~596 MB (factible para hardware est√°ndar)
* **Ventaja principal:** Latencia de red nula
* **Perfil operacional:** Modelo confiable para entornos con requisitos de disponibilidad constante

**Justificaci√≥n de selecci√≥n:** Representa la independencia operacional total. En escenarios donde la conectividad es limitada, las APIs no est√°n disponibles, o existen restricciones presupuestarias, Nomic Embed mantiene funcionalidad completa.

### üåü Gemini: API comercial de Google

**Caracter√≠sticas t√©cnicas:** Modelo de embeddings de Google con infraestructura cloud empresarial.

**Especificaciones:**

* **Dimensiones:** 1536 (alta dimensionalidad para representaci√≥n sem√°ntica compleja)
* **Velocidad:** 3-5 segundos por consulta
* **Calidad:** Comprensi√≥n contextual avanzada
* **Limitaciones:** 15 peticiones por minuto, 1000 peticiones por d√≠a (plan gratuito)

**Justificaci√≥n de selecci√≥n:** Gemini representa el estado actual de embeddings comerciales, combinando calidad sem√°ntica superior con la estabilidad y confiabilidad de la infraestructura de Google.

**Consideraciones del plan gratuito:** Al utilizar el tier gratuito de Gemini, estamos sujetos a limitaciones de 15 peticiones por minuto y 1000 peticiones diarias.

### üéØ Jina: API especializada en embeddings

**Caracter√≠sticas t√©cnicas:** Empresa especializada exclusivamente en embeddings y b√∫squeda vectorial.

**Especificaciones:**

* **Dimensiones:** 1024 (dimensionalidad intermedia)
* **Especializaci√≥n:** Optimizaci√≥n espec√≠fica para b√∫squeda vectorial
* **Plan:** Gratuito con 10 millones de tokens disponibles
* **Perfil operacional:** Modelo especializado con rendimiento variable seg√∫n disponibilidad del servicio

**Justificaci√≥n de selecci√≥n:** Jina ofrece una perspectiva especializada en el ecosistema de embeddings, proporcionando un punto de comparaci√≥n valioso entre soluciones locales y APIs comerciales de prop√≥sito general.

**Limitaciones del plan gratuito:** Jina ofrece 10 millones de tokens para procesar, pero al ser un plan experimental, las peticiones se procesan con baja prioridad, resultando en tiempos de respuesta variables.

### Consideraciones de servicios en la nube

**Tanto Gemini como Jina operan bajo planes gratuitos**, lo que introduce algunas limitaciones operacionales importantes que explican parte de la variabilidad observada en los resultados, especialmente para Jina que mostr√≥ tiempos de respuesta de 30-50 segundos promedio.

Esta realidad hace que **Nomic Embed, pese a su menor calidad sem√°ntica, ofrezca ventajas significativas de autonom√≠a y predictibilidad operacional**.

## Metodolog√≠a de evaluaci√≥n: m√©todos nativos de DuckDB

Para garantizar una comparaci√≥n equitativa entre modelos, utilizamos los **m√©todos nativos de DuckDB** - funciones optimizadas (`array_cosine_similarity()` y `array_distance()`) que son **35-50 veces m√°s r√°pidas** que las implementaciones manuales en Python.

**Impacto en rendimiento:** La diferencia pr√°ctica es sustancial: pasar de b√∫squedas que requer√≠an 500-800ms a b√∫squedas optimizadas de 9-16ms. Esta mejora es comparable a la diferencia entre procesar datos manualmente versus utilizar algoritmos altamente optimizados.

### L2 vs Coseno: la eterna pregunta

**Distancia L2 (Euclidiana):** Mide qu√© tan "lejos" est√°n dos vectores en el espacio matem√°tico. Como medir la distancia entre dos puntos en un mapa.

**Similitud Coseno:** Mide qu√© tan "alineados" est√°n dos vectores, ignorando su magnitud. Como medir si dos flechas apuntan en la misma direcci√≥n, sin importar su tama√±o.

La pregunta que todos se hacen: **¬øimporta cu√°l usar?** Spoiler: menos de lo que pensar√≠as.

## Los resultados: cuando los n√∫meros hablan por s√≠ solos

### An√°lisis 1: Velocidad de b√∫squeda vectorial

| Modelo          | L2 (ms) | Coseno (ms) | Diferencia | Observaci√≥n                   |
| --------------- | ------- | ----------- | ---------- | ----------------------------- |
| **Nomic Embed** | 14.03   | 12.62       | +1.41ms    | Coseno ligeramente m√°s r√°pido |
| **Gemini**      | 16.20   | 14.12       | +2.08ms    | Coseno ligeramente m√°s r√°pido |
| **Jina**        | 11.69   | 9.21        | +2.48ms    | Coseno ligeramente m√°s r√°pido |

**Hallazgo importante:** La diferencia promedio de \~2ms entre L2 y Coseno es pr√°cticamente despreciable para aplicaciones en producci√≥n. Esta diferencia es comparable a debatir si una tarea se completa en 4.012 segundos versus 4.014 segundos: t√©cnicamente medible, pr√°cticamente irrelevante.

### An√°lisis 2: Rendimiento total (embedding + b√∫squeda)

Este an√°lisis examina no solo la velocidad de b√∫squeda, sino tambi√©n la velocidad de procesamiento para generar embeddings de nuevas consultas.

#### M√©trica L2

| Posici√≥n | Modelo          | Tiempo Total | Consultas/seg | Chunks/seg |
| -------- | --------------- | ------------ | ------------- | ---------- |
| 1¬∞       | **Nomic Embed** | 177ms        | 5.65          | 356.3      |
| 2¬∞       | **Gemini**      | 412ms        | 2.43          | 308.6      |
| 3¬∞       | **Jina**        | 49,684ms     | 0.02          | 427.5      |

#### M√©trica Coseno

| Posici√≥n | Modelo          | Tiempo Total | Consultas/seg | Chunks/seg |
| -------- | --------------- | ------------ | ------------- | ---------- |
| 1¬∞       | **Nomic Embed** | 201ms        | 4.97          | 396.2      |
| 2¬∞       | **Gemini**      | 391ms        | 2.55          | 354.2      |
| 3¬∞       | **Jina**        | 34,944ms     | 0.03          | 542.7      |

**Hallazgo importante:** Nomic Embed supera significativamente a los modelos basados en API en rendimiento total. Esta ventaja se debe a que mientras Gemini y Jina requieren transmisi√≥n de datos a trav√©s de internet, Nomic Embed procesa todo localmente. La diferencia es comparable a consultar informaci√≥n almacenada localmente versus realizar una llamada telef√≥nica a larga distancia.

#### Definici√≥n de m√©tricas de rendimiento

**Consultas/seg (Queries per Second):** Mide la **velocidad de procesamiento completo** de una consulta, incluyendo tanto la generaci√≥n del embedding como la b√∫squeda vectorial. Se calcula como el inverso del tiempo total promedio. Esta m√©trica representa la **capacidad del sistema para atender consultas de usuarios finales**.

**Chunks/seg (Chunks per Second):** Mide la **velocidad de procesamiento durante la fase de b√∫squeda √∫nicamente**, calculando cu√°ntos fragmentos de documento pueden ser procesados por segundo durante la comparaci√≥n vectorial. Esta m√©trica eval√∫a la **eficiencia del motor de b√∫squeda** independiente de la generaci√≥n de embeddings.

### An√°lisis 3: Calidad de respuestas

Evaluaci√≥n basada en la consulta: *"¬øC√≥mo pueden las personas ciudadanas afiliarse al IMSS-Bienestar?"*

#### Relevancia con L2

| Modelo          | Relevancia Promedio | Categor√≠a | Observaci√≥n                                |
| --------------- | ------------------- | --------- | ------------------------------------------ |
| **Gemini**      | 94.8%               | Excelente | Respuestas precisas y contextuales         |
| **Jina**        | 92.2%               | Excelente | Calidad equiparable, perspectiva diferente |
| **Nomic Embed** | 92.0%               | Muy buena | Funcional y confiable                      |

#### Relevancia con Coseno

| Modelo          | Relevancia Promedio | Categor√≠a | Observaci√≥n                   |
| --------------- | ------------------- | --------- | ----------------------------- |
| **Jina**        | 92.2%               | Excelente | Consistente en ambas m√©tricas |
| **Gemini**      | 68.1%               | Aceptable | Puntuaci√≥n m√°s conservadora   |
| **Nomic Embed** | 61.9%               | Aceptable | Puntuaci√≥n m√°s conservadora   |

**Hallazgo importante:** Ambas m√©tricas recuperan exactamente los mismos fragmentos de texto, pero L2 genera puntuaciones 30-35% m√°s optimistas que Coseno. L2 aplica una transformaci√≥n logar√≠tmica que favorece puntuaciones altas, mientras que Coseno proporciona una evaluaci√≥n m√°s directa de la similitud angular.

### An√°lisis 4: Estabilidad operacional

La variabilidad en el rendimiento es un factor cr√≠tico para sistemas en producci√≥n. Un modelo puede ser r√°pido y preciso, pero la inconsistencia operacional puede generar problemas significativos.

#### Desviaci√≥n est√°ndar en L2

| Modelo          | Embedding (ms) | B√∫squeda (ms) | Evaluaci√≥n                        |
| --------------- | -------------- | ------------- | --------------------------------- |
| **Gemini**      | 274.49         | 10.21         | Estable y confiable               |
| **Nomic Embed** | 1958.16        | 9.06          | Muy estable (procesamiento local) |
| **Jina**        | 4607.21        | 4.59          | Variable (servicio gratuito)      |

**Consideraciones operacionales:** Jina, como servicio experimental gratuito, presenta la mayor variabilidad en rendimiento. Gemini mantiene mayor consistencia gracias a su infraestructura empresarial. Nomic Embed demuestra estabilidad predecible debido a su naturaleza local.

### Robustez ante calidad de datos

Un hallazgo importante del an√°lisis es que **Nomic Embed requiere datos muy limpios para un rendimiento √≥ptimo**, mientras que **Gemini y Jina demuestran mayor robustez ante datos de calidad variable**.

Los datos no limpios afectan a todos los modelos incrementando:

* **Consumo de tokens y tiempo de procesamiento**
* **Agotamiento acelerado de cuotas** (relevante para APIs)
* **Sobrecarga computacional** por contenido mal estructurado

Esta consideraci√≥n es importante para la selecci√≥n de modelo seg√∫n la calidad de los datos de entrada disponibles.

## El an√°lisis visual: estructura del espacio vectorial

### ¬øQu√© nos dicen las visualizaciones?

Nuestro an√°lisis incluy√≥ extensas visualizaciones que revelan patrones importantes:

**Gr√°ficos de rendimiento:** Muestran claramente que la b√∫squeda vectorial es siempre ultrarr√°pida (menos de 17ms), mientras que la generaci√≥n de embeddings domina el tiempo total. Es como descubrir que en una carrera de relevos, todos los corredores son igualmente r√°pidos, pero algunos tardan mucho m√°s en recibir la estafeta.

### M√©tricas de rendimiento

#### Comparaci√≥n de velocidad (Performance Comparison)

Las gr√°ficas comparativas revelan que Nomic Embed es consistentemente el m√°s r√°pido en tiempo total, seguido por Gemini, mientras que Jina presenta alta variabilidad por las limitaciones del servicio gratuito.

* **M√©trica Coseno:** 
  ![](/images/posts/2025/08/comparacion-embeddings/metrics_native_coseno/performance_comparison_native.png)
* **M√©trica L2:** 
  ![](/images/posts/2025/08/comparacion-embeddings/metrics_native_l2/performance_comparison_native.png)

#### An√°lisis de throughput (Velocity & Throughput Comparison)

Estas visualizaciones confirman la superioridad de Nomic Embed en consultas/seg y la eficiencia equivalente en chunks/seg entre todos los modelos.

* **Velocity Comparison Coseno:**

![](/images/posts/2025/08/comparacion-embeddings/metrics_native_coseno/velocity_comparison_native.png)

* **Velocity Comparison L2:** ![](/images/posts/2025/08/comparacion-embeddings/metrics_native_l2/velocity_comparison_native.png)
* **Throughput Comparison Coseno:**

![](/images/posts/2025/08/comparacion-embeddings/metrics_native_coseno/throughput_comparison_native.png)

* **Throughput Comparison L2:** 

![](/images/posts/2025/08/comparacion-embeddings/metrics_native_l2/throughput_comparison_native.png)

#### Estabilidad temporal (Boxplots y Histogramas)

Los boxplots revelan que Gemini mantiene estabilidad empresarial, Nomic Embed presenta variaciones predecibles locales, y Jina muestra mayor dispersi√≥n por las limitaciones del tier gratuito.

* **Performance Boxplots Coseno:**![](/images/posts/2025/08/comparacion-embeddings/metrics_native_coseno/performance_boxplots_native.png)
* **Performance Boxplots L2:** ![](/images/posts/2025/08/comparacion-embeddings/metrics_native_l2/performance_boxplots_native.png)
* **Timing Histograms Coseno:** ![](/images/posts/2025/08/comparacion-embeddings/metrics_native_coseno/timing_histograms_native.png)
* **Timing Histograms L2:** ![](/images/posts/2025/08/comparacion-embeddings/metrics_native_l2/timing_histograms_native.png)
* **Timing Scatter Coseno:** ![](/images/posts/2025/08/comparacion-embeddings/metrics_native_coseno/timing_scatter_native.png)\`\`
* **Timing Scatter L2:** ![](/images/posts/2025/08/comparacion-embeddings/metrics_native_l2/timing_scatter_native.png)\`\`

### Visualizaciones del espacio vectorial

**Proyecciones t-SNE:** Estas representaciones 2D del espacio vectorial multidimensional revelaron un hallazgo crucial: **la estructura espacial de los embeddings es pr√°cticamente id√©ntica entre L2 y Coseno**. Los documentos se agrupan de la misma manera, las consultas caen en los mismos lugares. Solo cambia la forma de medir las distancias.

#### Estructura de clusters por modelo

Las proyecciones t-SNE muestran c√≥mo cada modelo organiza el contenido en el espacio vectorial:

* **Gemini Chunks:**
* ![](/images/posts/2025/08/comparacion-embeddings/tsne_native_coseno/tsne_gemini_chunks_native.png)
* **Jina Chunks:** ![](/images/posts/2025/08/comparacion-embeddings/tsne_native_coseno/tsne_jina_chunks_native.png)
* **Nomic Embed Chunks:** ![](/images/posts/2025/08/comparacion-embeddings/tsne_native_coseno/tsne_nomic_chunks_native.png)

#### An√°lisis de overlays por modelo y m√©trica

Los overlays revelan c√≥mo las consultas se posicionan respecto a los clusters de contenido:

**Gemini Overlays:**

* ![](/images/posts/2025/08/comparacion-embeddings/tsne_native_coseno/tsne_gemini_overlay_native.png)

**Jina Overlays:**

* **Coseno:**![](/images/posts/2025/08/comparacion-embeddings/tsne_native_coseno/tsne_jina_overlay_native.png)
* **L2:** ![](/images/posts/2025/08/comparacion-embeddings/tsne_native_l2/tsne_jina_overlay_native.png)

**Nomic Embed Overlays:**

* ![](/images/posts/2025/08/comparacion-embeddings/tsne_native_coseno/tsne_nomic_overlay_native.png)

**Visualizaciones por modelo:**

* **Gemini y Nomic Embed:** Los overlays son pr√°cticamente id√©nticos entre m√©tricas
* **Jina:** Es el √∫nico modelo que presenta ligeras variaciones en los overlays entre m√©tricas

Las visualizaciones apoyan las conclusiones num√©ricas: **misma recuperaci√≥n de contenido, diferencias solo en la escala de relevancia**.

## La dimensionalidad importa (pero no como esperar√≠as)

Un hallazgo contraintuitivo: **Jina (1024D) es el m√°s r√°pido en b√∫squedas**, seguido por Nomic Embed (768D) y finalmente Gemini (1536D). Esto desaf√≠a la intuici√≥n de que m√°s dimensiones = m√°s lentitud. La realidad es que la optimizaci√≥n del algoritmo y la implementaci√≥n importan m√°s que el n√∫mero bruto de dimensiones.

## Aspectos t√©cnicos: bajo el cap√≥

### C√≥mo convertimos distancias en porcentajes

**Para L2 (Distancia Euclidiana):**

```
relevancia = 100.0 / (1.0 + distancia / 10.0)
```

Esta f√≥rmula logar√≠tmica comprime las diferencias, haciendo que distancias peque√±as se traduzcan en relevencias muy altas.

**Para Coseno (Similitud Angular):**

```
relevancia = similitud x 100.0
```

Una conversi√≥n directa y lineal que refleja exactamente la similitud angular.

### Los l√≠mites operacionales

Los servicios de API presentan limitaciones que influyen en el rendimiento:

**Gemini:** 15 peticiones por minuto, 1000 peticiones por d√≠a
**Jina:** 10 millones de tokens, procesamiento con baja prioridad

Estas limitaciones explican parcialmente la variabilidad observada en los tiempos de respuesta y hacen que soluciones locales como Nomic Embed ofrezcan ventajas de predictibilidad.

## Conclusiones: cuando la teor√≠a se encuentra con la realidad

### Evaluaci√≥n comparativa final

**Para velocidad y autonom√≠a operacional:** **Nomic Embed** demuestra superioridad clara. Sin dependencias externas, sin l√≠mites de API, con rendimiento predecible. Representa una soluci√≥n robusta y aut√≥noma para entornos con requisitos de disponibilidad constante.

**Para calidad sem√°ntica superior:** **Gemini** ofrece la mejor experiencia cuando la precisi√≥n es prioritaria. Proporciona embeddings de alta calidad con infraestructura empresarial confiable, aunque con limitaciones de uso que requieren planificaci√≥n.

**Para balance calidad-disponibilidad:** **Jina** ofrece buen rendimiento cuando el servicio opera √≥ptimamente. √ötil como alternativa especializada, aunque con variabilidad inherente a servicios gratuitos.

### L2 vs Coseno: an√°lisis comparativo

Despu√©s de 42 consultas y an√°lisis exhaustivos, los datos muestran que **ambas m√©tricas son funcionalmente equivalentes**. Las diferencias principales:

* Recuperan exactamente el mismo contenido
* Diferencias de velocidad m√≠nimas (\~2ms)
* Mantienen estructura espacial id√©ntica
* Solo difieren en escalas de puntuaci√≥n

La selecci√≥n entre ambas puede basarse en preferencias de interpretaci√≥n: Coseno ofrece puntuaciones m√°s conservadoras y directamente interpretables, mientras que L2 proporciona puntuaciones m√°s optimistas debido a su transformaci√≥n logar√≠tmica.

### La estrategia h√≠brida: lo mejor de ambos mundos

Para proyectos grandes como DOF-RAG, la soluci√≥n √≥ptima es una **estrategia h√≠brida**:

1. **Gemini para documentos cr√≠ticos** donde la precisi√≥n es fundamental
2. **Nomic Embed para procesamiento masivo** donde podemos aceptar un margen de error mayor
3. **Jina como respaldo** para casos especiales que requieren una perspectiva diferente

### Recomendaciones pr√°cticas

**Para autonom√≠a operacional completa:** Nomic Embed es la elecci√≥n √≥ptima. El sistema nunca depender√° de APIs externas y mantendr√° rendimiento predecible.

**Para m√°xima calidad sem√°ntica:** Gemini ofrece la mejor experiencia cuando la precisi√≥n es prioritaria, aunque requiere gesti√≥n de l√≠mites de API.

**Para experimentaci√≥n con presupuesto limitado:** Jina proporciona una opci√≥n viable para prototipos, aunque con variabilidad en tiempos de respuesta.

**Sobre selecci√≥n de m√©trica:** Coseno para puntuaciones conservadoras e interpretables; L2 para puntuaciones optimistas. Ambas ofrecen rendimiento equivalente en recuperaci√≥n de contenido.

## Reflexiones finales: el futuro de la b√∫squeda sem√°ntica

Este an√°lisis nos ha ense√±ado que en el mundo de los embeddings, como en muchos aspectos de la tecnolog√≠a, no existe una soluci√≥n √∫nica que sea perfecta para todos los casos. La elecci√≥n del modelo correcto depende de tus prioridades espec√≠ficas: ¬øautonom√≠a o calidad? ¬øvelocidad o precisi√≥n? ¬øcosto o rendimiento?

Lo que s√≠ queda claro es que los embeddings vectoriales han democratizado la b√∫squeda sem√°ntica sofisticada. Modelos que hace unos a√±os requer√≠an infraestructuras millonarias ahora pueden ejecutarse en una laptop modesta. El futuro de la b√∫squeda inteligente no est√° en manos de unos pocos gigantes tecnol√≥gicos, sino al alcance de cualquiera con curiosidad suficiente para experimentar.

Y quiz√°s esa sea la lecci√≥n m√°s importante: en la era de la IA, el conocimiento t√©cnico sigue siendo poder, pero el poder real est√° en saber c√≥mo aplicar esas herramientas para resolver problemas reales de personas reales.

***

*Este an√°lisis forma parte de nuestro proyecto DOF-RAG para hacer m√°s accesible la informaci√≥n gubernamental mexicana. Para m√°s detalles t√©cnicos, metodolog√≠a completa y acceso al c√≥digo fuente, consulta [nuestro repositorio](https://github.com/CodeandoGuadalajara/dof-rag).*

**Datos del an√°lisis:**

* **Per√≠odo de evaluaci√≥n:** Agosto 2025
* **Consultas analizadas:** 42 preguntas representativas
* **Fragmentos procesados:** M√°s de 1000 chunks de documentos DOF
* **Herramientas utilizadas:** DuckDB, Python, m√©todos nativos de similitud vectorial
